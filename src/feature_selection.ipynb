{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Feature selection by a cross-validation using random forest classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import *\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_score, recall_score, precision_recall_curve,f1_score, fbeta_score\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.set_option(\"display.max_rows\", 999)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"precision\", 3)\n",
    "sns.set_context(\"talk\") # talk context is good for RISE presentations\n",
    "%pylab inline\n",
    "%config InlineBackend.figure_formats = ['retina']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load clean data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>derived_msa_md</th>\n",
       "      <th>county_code</th>\n",
       "      <th>conforming_loan_limit</th>\n",
       "      <th>derived_loan_product_type</th>\n",
       "      <th>derived_race</th>\n",
       "      <th>derived_sex</th>\n",
       "      <th>lien_status</th>\n",
       "      <th>open_end_line_of_credit</th>\n",
       "      <th>business_or_commercial_purpose</th>\n",
       "      <th>hoepa_status</th>\n",
       "      <th>interest_only_payment</th>\n",
       "      <th>balloon_payment</th>\n",
       "      <th>occupancy_type</th>\n",
       "      <th>total_units</th>\n",
       "      <th>applicant_race_1</th>\n",
       "      <th>applicant_sex</th>\n",
       "      <th>applicant_age_above_62</th>\n",
       "      <th>co_applicant_age_above_62</th>\n",
       "      <th>loan_term</th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>property_value</th>\n",
       "      <th>loan_to_value_ratio</th>\n",
       "      <th>income</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>total_age</th>\n",
       "      <th>applicant_age</th>\n",
       "      <th>co_applicant_age</th>\n",
       "      <th>action_taken</th>\n",
       "      <th>denial_reason_1</th>\n",
       "      <th>denial_reason_2</th>\n",
       "      <th>denial_reason_3</th>\n",
       "      <th>denial_reason_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15764</td>\n",
       "      <td>25017</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>180</td>\n",
       "      <td>265,000.00</td>\n",
       "      <td>815000</td>\n",
       "      <td>32.10</td>\n",
       "      <td>114.00</td>\n",
       "      <td>33</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15764</td>\n",
       "      <td>25009</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Race Not Available</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>No info.</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>300</td>\n",
       "      <td>265,000.00</td>\n",
       "      <td>525000</td>\n",
       "      <td>50.29</td>\n",
       "      <td>89.00</td>\n",
       "      <td>25</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15764</td>\n",
       "      <td>25017</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>White</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>N/A</td>\n",
       "      <td>360</td>\n",
       "      <td>305,000.00</td>\n",
       "      <td>575000</td>\n",
       "      <td>52.27</td>\n",
       "      <td>75.00</td>\n",
       "      <td>45</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  derived_msa_md county_code conforming_loan_limit derived_loan_product_type  \\\n",
       "0          15764       25017                     C                     First   \n",
       "1          15764       25009                     C                     First   \n",
       "2          15764       25017                     C                     First   \n",
       "\n",
       "         derived_race derived_sex lien_status open_end_line_of_credit  \\\n",
       "0               White        Male           1                       2   \n",
       "1  Race Not Available        Male           1                       2   \n",
       "2               White        Male           1                       2   \n",
       "\n",
       "  business_or_commercial_purpose hoepa_status interest_only_payment  \\\n",
       "0                              2            2                     2   \n",
       "1                              1            3                     2   \n",
       "2                              2            2                     2   \n",
       "\n",
       "  balloon_payment occupancy_type total_units applicant_race_1 applicant_sex  \\\n",
       "0               2              1           1            White             1   \n",
       "1               2              3           2         No info.             1   \n",
       "2               2              1           1            White             1   \n",
       "\n",
       "  applicant_age_above_62 co_applicant_age_above_62  loan_term  loan_amount  \\\n",
       "0                     No                       N/A        180   265,000.00   \n",
       "1                     No                       N/A        300   265,000.00   \n",
       "2                     No                       N/A        360   305,000.00   \n",
       "\n",
       "   property_value  loan_to_value_ratio  income  debt_to_income_ratio  \\\n",
       "0          815000                32.10  114.00                    33   \n",
       "1          525000                50.29   89.00                    25   \n",
       "2          575000                52.27   75.00                    45   \n",
       "\n",
       "   total_age  applicant_age  co_applicant_age  action_taken  denial_reason_1  \\\n",
       "0         40             40                 0             1               10   \n",
       "1         30             30                 0             1               10   \n",
       "2         40             40                 0             1               10   \n",
       "\n",
       "   denial_reason_2  denial_reason_3  denial_reason_4  \n",
       "0              nan              nan              nan  \n",
       "1              nan              nan              nan  \n",
       "2              nan              nan              nan  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = \"\"\"\n",
    "SELECT * from ma_refinance_new\n",
    "\"\"\"\n",
    "df = do(q)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **1.1 Separate categorical and continuous variables to facilitate OneHotEncoding incross validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cat = gen_cat(df)\n",
    "x_cont = gen_cont(df)\n",
    "y = df[['action_taken']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Run randomized search cross-validation**\n",
    " Randomized search cv gives similar results to that from grid search cv, but it leads to drastically low computation cost.  \n",
    " Refs:\n",
    " [sklearn doc](https://scikit-learn.org/stable/auto_examples/model_selection/plot_randomized_search.html)\n",
    " [Hyperparameter Tuning the Random Forest in Python](https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.1. Split the data**\n",
    " Split the data into training and testing datasets (70% vs. 30%). Also, split testing dataset into validation and testing datasets (30% vs 70%). The validation dataset is used to generate permutation feature importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to \"../data/data_vf.pickle\"\n"
     ]
    }
   ],
   "source": [
    "categorical_columns = list(x_cat.columns)\n",
    "numerical_columns = list(x_cont.columns)\n",
    "x = df[categorical_columns + numerical_columns]\n",
    "#-------------------------------------------------------------------------\n",
    "testing_portion = 0.3\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, stratify=y, random_state=15, test_size=testing_portion)\n",
    "#-------------------------------------------------------------------------\n",
    "validation_portion = 0.3\n",
    "x_test, x_val, y_test, y_val = train_test_split(\n",
    "    x_test, y_test, stratify=y_test, random_state=15, test_size=validation_portion)\n",
    "\n",
    "data_dict = make_data_dict(x_train, y_train,\n",
    "                           x_test, y_test,\n",
    "                           x_val, y_val,\n",
    "                           )\n",
    "fn = '../data/data_vf.pickle'\n",
    "save_as_pickle(fn, data_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2.2 Run randomized search cross-validation using random forest classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classifier__n_estimators': [100, 200, 300, 400, 500], 'classifier__max_features': ['auto', 'sqrt', 'log2'], 'classifier__max_depth': [10, 15, 21, 27, 32, 38, 44, 50, None], 'classifier__min_samples_split': [2, 5, 10, 15, 20], 'classifier__min_samples_leaf': [1, 2, 4], 'classifier__bootstrap': [True, False]}\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:   35.3s\n",
      "[Parallel(n_jobs=-1)]: Done 138 tasks      | elapsed:  2.4min\n",
      "[Parallel(n_jobs=-1)]: Done 341 tasks      | elapsed:  5.7min\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  8.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved data to \"../data/rf_pipeline.pickle\"\n"
     ]
    }
   ],
   "source": [
    "random_grid = gen_hypergrid_for_rf_cv()\n",
    "base_mdl = RandomForestClassifier()\n",
    "rf_random = make_cv_pipelinie(base_mdl,\n",
    "                              categorical_columns,\n",
    "                              numerical_columns,\n",
    "                              random_grid,\n",
    "                              scoring='roc_auc'\n",
    "                             )\n",
    "rf_random.fit(x_train, y_train)\n",
    "\n",
    "# save the pipeline model\n",
    "fn = '../data/rf_pipeline.pickle'\n",
    "save_as_pickle(fn, rf_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Get permutation importance using the validation dataset generated in section 2.1**\n",
    "- Impurity-based feature importance can inflate the importance of numerical features.\n",
    "- The impurity-based feature importance of random forests suffers from being computed on statistics derived from the training dataset: the importances can be high even for features that are not predictive of the target variable, as long as the model has the capacity to use them to overfit.\n",
    "\n",
    "Ref: [Permutation Importance vs Random Forest Feature Importance (MDI)](https://scikit-learn.org/stable/auto_examples/inspection/plot_permutation_importance.html#sphx-glr-auto-examples-inspection-plot-permutation-importance-py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read data from \"../data/rf_pipeline.pickle\"\n"
     ]
    }
   ],
   "source": [
    "fn = '../data/rf_pipeline.pickle'\n",
    "rf_random = read_from_pickle(fn)\n",
    "result = permutation_importance(rf_random.best_estimator_, x_val, y_val, n_repeats=10,\n",
    "                                random_state=15, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_idx = result.importances_mean.argsort()[::-1]\n",
    "mean_importance = result.importances_mean[sorted_idx]\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax = sns.barplot(x=mean_importance,\n",
    "                 y=x_test.columns[sorted_idx],\n",
    "                color=[0.2, 0.4, 0.6])\n",
    "ax.set_ylim([15, -0.5])\n",
    "ax.set_title(\"Permutation Importance (Validation set)\")\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.savefig(\"../figures/feat_sel_permut_importance.svg\",\n",
    "            dpi=300, bbox_inches='tight', facecolor=\"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = np.percentile(mean_importance, 75)\n",
    "idx_sel_feat_sorted = mean_importance > thresh\n",
    "idx_sel_feat = sorted_idx[idx_sel_feat_sorted]\n",
    "fn = '../data/idx_sel_feat_permu_importance.pickle'\n",
    "save_as_pickle(fn, idx_sel_feat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
